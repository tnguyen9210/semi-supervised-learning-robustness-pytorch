INFO: Running with the following configs:
	seed : 0
	device : cuda:0
	data_dir : ../../data/svhn_v11
	domain : svhn_orig
	img_size : 32
	num_epochs : 150
	num_iters : 500000
	num_iters_per_epoch : 3000
	batch_size : 100
	consis_warmup : 200000
	vat_niters : 1
	vat_eps : 2.0
	vat_xi : 1e-06
	vat_consis_coef : 0.3
	optim : sgd
	lr : 0.05
	momentum : 0.9
	l2_params : 0.0005
	max_grad_norm : 1
	scheduler_t0 : 10
	scheduler_tmult : 2
	resnet_depth : 28
	resnet_widen_factor : 2
	resnet_group1_droprate : 0.3
	resnet_group2_droprate : 0.3
	resnet_group3_droprate : 0.3
	img_cls_nlayers : 2
	img_cls_hidden_dim1 : 128
	img_cls_hidden_dim2 : 128
	img_cls_droprate1 : 0.5
	img_cls_droprate2 : 0.5
	model_id : 10
	model_dir : ./saved_models
	eval_set : test_lbl
	ckpt_name : best_model.ckpt
	load : False

INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 0, it 751 >> 25.03 (41.829 sec) : loss = 1.03691
INFO: epoch 0, it 1502 >> 50.07 (83.364 sec) : loss = 0.29045
INFO: epoch 0, it 2253 >> 75.10 (124.829 sec) : loss = 0.20765
INFO: epoch 0  >> 100.00 (166.005 sec) : lr 0.0500, train loss 0.73023
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 12.1
INFO: test : error = 11.4667
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 1, it 3751 >> 25.03 (41.695 sec) : loss = 0.16221
INFO: epoch 1, it 4502 >> 50.07 (83.433 sec) : loss = 0.12208
INFO: epoch 1, it 5253 >> 75.10 (124.971 sec) : loss = 0.21509
INFO: epoch 1  >> 100.00 (166.265 sec) : lr 0.0488, train loss 0.15925
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 10.5
INFO: test : error = 9.7841
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 2, it 6751 >> 25.03 (41.633 sec) : loss = 0.10122
INFO: epoch 2, it 7502 >> 50.07 (83.362 sec) : loss = 0.18513
INFO: epoch 2, it 8253 >> 75.10 (125.050 sec) : loss = 0.16294
INFO: epoch 2  >> 100.00 (166.346 sec) : lr 0.0452, train loss 0.14578
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.8
INFO: test : error = 9.9032
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 3, it 9751 >> 25.03 (41.545 sec) : loss = 0.13961
INFO: epoch 3, it 10502 >> 50.07 (83.221 sec) : loss = 0.13901
INFO: epoch 3, it 11253 >> 75.10 (124.758 sec) : loss = 0.08073
INFO: epoch 3  >> 100.00 (166.031 sec) : lr 0.0397, train loss 0.12962
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.8
INFO: test : error = 7.9633
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 4, it 12751 >> 25.03 (41.718 sec) : loss = 0.08709
INFO: epoch 4, it 13502 >> 50.07 (83.456 sec) : loss = 0.09066
INFO: epoch 4, it 14253 >> 75.10 (125.036 sec) : loss = 0.09360
INFO: epoch 4  >> 100.00 (166.311 sec) : lr 0.0327, train loss 0.11644
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.1
INFO: test : error = 7.4677
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 5, it 15751 >> 25.03 (41.605 sec) : loss = 0.14398
INFO: epoch 5, it 16502 >> 50.07 (83.349 sec) : loss = 0.06775
INFO: epoch 5, it 17253 >> 75.10 (124.974 sec) : loss = 0.12310
INFO: epoch 5  >> 100.00 (166.330 sec) : lr 0.0250, train loss 0.10276
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.9
INFO: test : error = 8.0132
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 6, it 18751 >> 25.03 (41.645 sec) : loss = 0.06124
INFO: epoch 6, it 19502 >> 50.07 (83.308 sec) : loss = 0.11559
INFO: epoch 6, it 20253 >> 75.10 (124.886 sec) : loss = 0.10857
INFO: epoch 6  >> 100.00 (166.218 sec) : lr 0.0173, train loss 0.08725
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.3
INFO: test : error = 7.2372
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 7, it 21751 >> 25.03 (41.667 sec) : loss = 0.11496
INFO: epoch 7, it 22502 >> 50.07 (83.425 sec) : loss = 0.08286
INFO: epoch 7, it 23253 >> 75.10 (125.057 sec) : loss = 0.07903
INFO: epoch 7  >> 100.00 (166.360 sec) : lr 0.0103, train loss 0.07516
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.3
INFO: test : error = 6.4344
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 8, it 24751 >> 25.03 (41.628 sec) : loss = 0.02869
INFO: epoch 8, it 25502 >> 50.07 (83.340 sec) : loss = 0.04668
INFO: epoch 8, it 26253 >> 75.10 (124.933 sec) : loss = 0.08552
INFO: epoch 8  >> 100.00 (166.252 sec) : lr 0.0048, train loss 0.06364
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.2
INFO: test : error = 6.0695
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 9, it 27751 >> 25.03 (41.712 sec) : loss = 0.04645
INFO: epoch 9, it 28502 >> 50.07 (83.425 sec) : loss = 0.02366
INFO: epoch 9, it 29253 >> 75.10 (125.078 sec) : loss = 0.04775
INFO: epoch 9  >> 100.00 (166.410 sec) : lr 0.0012, train loss 0.05680
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.6
INFO: test : error = 5.3972
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 10, it 30751 >> 25.03 (41.801 sec) : loss = 0.15106
INFO: epoch 10, it 31502 >> 50.07 (83.426 sec) : loss = 0.13033
INFO: epoch 10, it 32253 >> 75.10 (125.026 sec) : loss = 0.10559
INFO: epoch 10  >> 100.00 (166.331 sec) : lr 0.0500, train loss 0.17542
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.1
INFO: test : error = 7.4293
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 11, it 33751 >> 25.03 (41.807 sec) : loss = 0.15933
INFO: epoch 11, it 34502 >> 50.07 (83.455 sec) : loss = 0.07412
INFO: epoch 11, it 35253 >> 75.10 (125.128 sec) : loss = 0.13513
INFO: epoch 11  >> 100.00 (166.503 sec) : lr 0.0497, train loss 0.13608
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 7.6944
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 12, it 36751 >> 25.03 (41.672 sec) : loss = 0.15645
INFO: epoch 12, it 37502 >> 50.07 (83.078 sec) : loss = 0.12442
INFO: epoch 12, it 38253 >> 75.10 (124.496 sec) : loss = 0.15338
INFO: epoch 12  >> 100.00 (165.639 sec) : lr 0.0488, train loss 0.13061
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.3
INFO: test : error = 9.4269
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 13, it 39751 >> 25.03 (41.646 sec) : loss = 0.16511
INFO: epoch 13, it 40502 >> 50.07 (83.148 sec) : loss = 0.09987
INFO: epoch 13, it 41253 >> 75.10 (124.585 sec) : loss = 0.17627
INFO: epoch 13  >> 100.00 (165.736 sec) : lr 0.0473, train loss 0.12894
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.2
INFO: test : error = 8.7277
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 14, it 42751 >> 25.03 (41.576 sec) : loss = 0.15875
INFO: epoch 14, it 43502 >> 50.07 (82.991 sec) : loss = 0.06501
INFO: epoch 14, it 44253 >> 75.10 (124.472 sec) : loss = 0.09479
INFO: epoch 14  >> 100.00 (165.658 sec) : lr 0.0452, train loss 0.12656
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.3
INFO: test : error = 7.6521
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 15, it 45751 >> 25.03 (41.614 sec) : loss = 0.08386
INFO: epoch 15, it 46502 >> 50.07 (83.027 sec) : loss = 0.11076
INFO: epoch 15, it 47253 >> 75.10 (124.447 sec) : loss = 0.11451
INFO: epoch 15  >> 100.00 (165.600 sec) : lr 0.0427, train loss 0.12090
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.2
INFO: test : error = 8.0171
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 16, it 48751 >> 25.03 (41.653 sec) : loss = 0.08141
INFO: epoch 16, it 49502 >> 50.07 (83.167 sec) : loss = 0.15135
INFO: epoch 16, it 50253 >> 75.10 (124.655 sec) : loss = 0.09258
INFO: epoch 16  >> 100.00 (165.809 sec) : lr 0.0397, train loss 0.11591
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.0
INFO: test : error = 7.268
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 17, it 51751 >> 25.03 (41.575 sec) : loss = 0.17674
INFO: epoch 17, it 52502 >> 50.07 (83.025 sec) : loss = 0.07163
INFO: epoch 17, it 53253 >> 75.10 (124.533 sec) : loss = 0.07987
INFO: epoch 17  >> 100.00 (165.773 sec) : lr 0.0363, train loss 0.11163
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.0
INFO: test : error = 6.8032
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 18, it 54751 >> 25.03 (41.593 sec) : loss = 0.10768
INFO: epoch 18, it 55502 >> 50.07 (83.010 sec) : loss = 0.11499
INFO: epoch 18, it 56253 >> 75.10 (124.381 sec) : loss = 0.15716
INFO: epoch 18  >> 100.00 (165.452 sec) : lr 0.0327, train loss 0.10635
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.4
INFO: test : error = 7.6175
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 19, it 57751 >> 25.03 (41.625 sec) : loss = 0.09077
INFO: epoch 19, it 58502 >> 50.07 (83.103 sec) : loss = 0.08061
INFO: epoch 19, it 59253 >> 75.10 (124.567 sec) : loss = 0.13299
INFO: epoch 19  >> 100.00 (165.763 sec) : lr 0.0289, train loss 0.09988
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.6
INFO: test : error = 6.8531
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 20, it 60751 >> 25.03 (41.608 sec) : loss = 0.05922
INFO: epoch 20, it 61502 >> 50.07 (83.016 sec) : loss = 0.14013
INFO: epoch 20, it 62253 >> 75.10 (124.430 sec) : loss = 0.08297
INFO: epoch 20  >> 100.00 (165.563 sec) : lr 0.0250, train loss 0.09434
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.8
INFO: test : error = 7.2949
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 21, it 63751 >> 25.03 (41.622 sec) : loss = 0.05536
INFO: epoch 21, it 64502 >> 50.07 (83.112 sec) : loss = 0.08670
INFO: epoch 21, it 65253 >> 75.10 (124.648 sec) : loss = 0.08519
INFO: epoch 21  >> 100.00 (165.865 sec) : lr 0.0211, train loss 0.08884
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.7
INFO: test : error = 6.9952
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 22, it 66751 >> 25.03 (41.574 sec) : loss = 0.06109
INFO: epoch 22, it 67502 >> 50.07 (83.044 sec) : loss = 0.05981
INFO: epoch 22, it 68253 >> 75.10 (124.436 sec) : loss = 0.04201
INFO: epoch 22  >> 100.00 (165.531 sec) : lr 0.0173, train loss 0.08434
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.6
INFO: test : error = 6.7225
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 23, it 69751 >> 25.03 (41.505 sec) : loss = 0.07781
INFO: epoch 23, it 70502 >> 50.07 (82.936 sec) : loss = 0.08778
INFO: epoch 23, it 71253 >> 75.10 (124.434 sec) : loss = 0.09633
INFO: epoch 23  >> 100.00 (165.691 sec) : lr 0.0137, train loss 0.07663
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.0
INFO: test : error = 6.419
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 24, it 72751 >> 25.03 (41.559 sec) : loss = 0.04759
INFO: epoch 24, it 73502 >> 50.07 (83.014 sec) : loss = 0.08951
INFO: epoch 24, it 74253 >> 75.10 (124.504 sec) : loss = 0.05890
INFO: epoch 24  >> 100.00 (165.735 sec) : lr 0.0103, train loss 0.07052
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.6
INFO: test : error = 5.9926
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 25, it 75751 >> 25.03 (41.455 sec) : loss = 0.10659
INFO: epoch 25, it 76502 >> 50.07 (82.827 sec) : loss = 0.05982
INFO: epoch 25, it 77253 >> 75.10 (124.226 sec) : loss = 0.03543
INFO: epoch 25  >> 100.00 (165.489 sec) : lr 0.0073, train loss 0.06397
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.0
INFO: test : error = 6.081
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 26, it 78751 >> 25.03 (41.523 sec) : loss = 0.05194
INFO: epoch 26, it 79502 >> 50.07 (83.038 sec) : loss = 0.04296
INFO: epoch 26, it 80253 >> 75.10 (124.538 sec) : loss = 0.03692
INFO: epoch 26  >> 100.00 (165.798 sec) : lr 0.0048, train loss 0.05736
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.7
INFO: test : error = 5.5739
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 27, it 81751 >> 25.03 (41.489 sec) : loss = 0.05998
INFO: epoch 27, it 82502 >> 50.07 (82.934 sec) : loss = 0.03932
INFO: epoch 27, it 83253 >> 75.10 (124.360 sec) : loss = 0.03505
INFO: epoch 27  >> 100.00 (165.608 sec) : lr 0.0027, train loss 0.05193
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.5
INFO: test : error = 5.2628
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 28, it 84751 >> 25.03 (41.500 sec) : loss = 0.04482
INFO: epoch 28, it 85502 >> 50.07 (82.957 sec) : loss = 0.02437
INFO: epoch 28, it 86253 >> 75.10 (124.441 sec) : loss = 0.04314
INFO: epoch 28  >> 100.00 (165.718 sec) : lr 0.0012, train loss 0.04816
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.3
INFO: test : error = 4.8364
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 29, it 87751 >> 25.03 (41.413 sec) : loss = 0.04708
INFO: epoch 29, it 88502 >> 50.07 (82.814 sec) : loss = 0.01964
INFO: epoch 29, it 89253 >> 75.10 (124.208 sec) : loss = 0.03425
INFO: epoch 29  >> 100.00 (165.422 sec) : lr 0.0003, train loss 0.04621
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.0
INFO: test : error = 4.8517
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 30, it 90751 >> 25.03 (41.517 sec) : loss = 0.12776
INFO: epoch 30, it 91502 >> 50.07 (82.977 sec) : loss = 0.11904
INFO: epoch 30, it 92253 >> 75.10 (124.392 sec) : loss = 0.12002
INFO: epoch 30  >> 100.00 (165.605 sec) : lr 0.0500, train loss 0.18155
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 7.9518
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 31, it 93751 >> 25.03 (41.464 sec) : loss = 0.11452
INFO: epoch 31, it 94502 >> 50.07 (82.885 sec) : loss = 0.12163
INFO: epoch 31, it 95253 >> 75.10 (124.368 sec) : loss = 0.12563
INFO: epoch 31  >> 100.00 (165.696 sec) : lr 0.0499, train loss 0.13091
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.6
INFO: test : error = 8.2053
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 32, it 96751 >> 25.03 (41.476 sec) : loss = 0.05084
INFO: epoch 32, it 97502 >> 50.07 (82.919 sec) : loss = 0.18876
INFO: epoch 32, it 98253 >> 75.10 (124.388 sec) : loss = 0.19869
INFO: epoch 32  >> 100.00 (165.643 sec) : lr 0.0497, train loss 0.12913
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.6
INFO: test : error = 7.8365
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 33, it 99751 >> 25.03 (41.545 sec) : loss = 0.05767
INFO: epoch 33, it 100502 >> 50.07 (83.040 sec) : loss = 0.06054
INFO: epoch 33, it 101253 >> 75.10 (124.517 sec) : loss = 0.15578
INFO: epoch 33  >> 100.00 (165.810 sec) : lr 0.0493, train loss 0.12519
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.6
INFO: test : error = 8.2783
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 34, it 102751 >> 25.03 (41.443 sec) : loss = 0.09059
INFO: epoch 34, it 103502 >> 50.07 (82.828 sec) : loss = 0.15670
INFO: epoch 34, it 104253 >> 75.10 (124.275 sec) : loss = 0.18671
INFO: epoch 34  >> 100.00 (165.573 sec) : lr 0.0488, train loss 0.12676
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 7.3333
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 35, it 105751 >> 25.03 (41.515 sec) : loss = 0.12964
INFO: epoch 35, it 106502 >> 50.07 (83.004 sec) : loss = 0.12179
INFO: epoch 35, it 107253 >> 75.10 (124.446 sec) : loss = 0.09960
INFO: epoch 35  >> 100.00 (165.631 sec) : lr 0.0481, train loss 0.12270
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.8
INFO: test : error = 7.6675
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 36, it 108751 >> 25.03 (41.452 sec) : loss = 0.07124
INFO: epoch 36, it 109502 >> 50.07 (82.888 sec) : loss = 0.12850
INFO: epoch 36, it 110253 >> 75.10 (124.397 sec) : loss = 0.10306
INFO: epoch 36  >> 100.00 (165.639 sec) : lr 0.0473, train loss 0.12283
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.3
INFO: test : error = 7.6713
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 37, it 111751 >> 25.03 (41.523 sec) : loss = 0.13136
INFO: epoch 37, it 112502 >> 50.07 (83.010 sec) : loss = 0.18872
INFO: epoch 37, it 113253 >> 75.10 (124.566 sec) : loss = 0.16961
INFO: epoch 37  >> 100.00 (165.761 sec) : lr 0.0463, train loss 0.11996
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.2
INFO: test : error = 8.4435
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 38, it 114751 >> 25.03 (41.508 sec) : loss = 0.18482
INFO: epoch 38, it 115502 >> 50.07 (82.997 sec) : loss = 0.13199
INFO: epoch 38, it 116253 >> 75.10 (124.526 sec) : loss = 0.11662
INFO: epoch 38  >> 100.00 (165.778 sec) : lr 0.0452, train loss 0.11821
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 7.291
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 39, it 117751 >> 25.03 (41.538 sec) : loss = 0.08206
INFO: epoch 39, it 118502 >> 50.07 (83.035 sec) : loss = 0.13257
INFO: epoch 39, it 119253 >> 75.10 (124.564 sec) : loss = 0.12286
INFO: epoch 39  >> 100.00 (165.754 sec) : lr 0.0440, train loss 0.11793
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.8
INFO: test : error = 8.0132
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 40, it 120751 >> 25.03 (41.469 sec) : loss = 0.21262
INFO: epoch 40, it 121502 >> 50.07 (82.851 sec) : loss = 0.14166
INFO: epoch 40, it 122253 >> 75.10 (124.399 sec) : loss = 0.11169
INFO: epoch 40  >> 100.00 (165.606 sec) : lr 0.0427, train loss 0.11663
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.8
INFO: test : error = 9.5767
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 41, it 123751 >> 25.03 (41.539 sec) : loss = 0.09871
INFO: epoch 41, it 124502 >> 50.07 (83.090 sec) : loss = 0.06095
INFO: epoch 41, it 125253 >> 75.10 (124.753 sec) : loss = 0.10491
INFO: epoch 41  >> 100.00 (165.943 sec) : lr 0.0412, train loss 0.11232
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.9
INFO: test : error = 6.8608
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 42, it 126751 >> 25.03 (41.557 sec) : loss = 0.07992
INFO: epoch 42, it 127502 >> 50.07 (83.026 sec) : loss = 0.10416
INFO: epoch 42, it 128253 >> 75.10 (124.591 sec) : loss = 0.08264
INFO: epoch 42  >> 100.00 (165.687 sec) : lr 0.0397, train loss 0.11243
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.5
INFO: test : error = 7.9095
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 43, it 129751 >> 25.03 (41.470 sec) : loss = 0.13308
INFO: epoch 43, it 130502 >> 50.07 (82.957 sec) : loss = 0.11263
INFO: epoch 43, it 131253 >> 75.10 (124.595 sec) : loss = 0.10746
INFO: epoch 43  >> 100.00 (165.842 sec) : lr 0.0381, train loss 0.11091
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.0
INFO: test : error = 8.5088
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 44, it 132751 >> 25.03 (41.519 sec) : loss = 0.12293
INFO: epoch 44, it 133502 >> 50.07 (82.982 sec) : loss = 0.09329
INFO: epoch 44, it 134253 >> 75.10 (124.524 sec) : loss = 0.09117
INFO: epoch 44  >> 100.00 (165.622 sec) : lr 0.0363, train loss 0.10751
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.0
INFO: test : error = 7.5369
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 45, it 135751 >> 25.03 (41.453 sec) : loss = 0.11200
INFO: epoch 45, it 136502 >> 50.07 (82.883 sec) : loss = 0.06877
INFO: epoch 45, it 137253 >> 75.10 (124.427 sec) : loss = 0.10072
INFO: epoch 45  >> 100.00 (165.557 sec) : lr 0.0346, train loss 0.10558
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.8
INFO: test : error = 7.825
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 46, it 138751 >> 25.03 (41.538 sec) : loss = 0.07890
INFO: epoch 46, it 139502 >> 50.07 (83.062 sec) : loss = 0.11283
INFO: epoch 46, it 140253 >> 75.10 (124.664 sec) : loss = 0.11570
INFO: epoch 46  >> 100.00 (165.813 sec) : lr 0.0327, train loss 0.10392
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.2
INFO: test : error = 7.1604
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 47, it 141751 >> 25.03 (41.541 sec) : loss = 0.08343
INFO: epoch 47, it 142502 >> 50.07 (82.995 sec) : loss = 0.11595
INFO: epoch 47, it 143253 >> 75.10 (124.570 sec) : loss = 0.08272
INFO: epoch 47  >> 100.00 (165.725 sec) : lr 0.0308, train loss 0.09889
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.8
INFO: test : error = 6.7532
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 48, it 144751 >> 25.03 (41.469 sec) : loss = 0.11907
INFO: epoch 48, it 145502 >> 50.07 (82.984 sec) : loss = 0.08576
INFO: epoch 48, it 146253 >> 75.10 (124.584 sec) : loss = 0.09657
INFO: epoch 48  >> 100.00 (165.805 sec) : lr 0.0289, train loss 0.09948
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 7.4524
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 49, it 147751 >> 25.03 (41.487 sec) : loss = 0.08418
INFO: epoch 49, it 148502 >> 50.07 (82.976 sec) : loss = 0.08126
INFO: epoch 49, it 149253 >> 75.10 (124.454 sec) : loss = 0.10103
INFO: epoch 49  >> 100.00 (165.568 sec) : lr 0.0270, train loss 0.09503
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.9
INFO: test : error = 6.8032
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 50, it 150751 >> 25.03 (41.509 sec) : loss = 0.10185
INFO: epoch 50, it 151502 >> 50.07 (83.093 sec) : loss = 0.08701
INFO: epoch 50, it 152253 >> 75.10 (124.618 sec) : loss = 0.09809
INFO: epoch 50  >> 100.00 (165.761 sec) : lr 0.0250, train loss 0.09291
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.6
INFO: test : error = 6.9683
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 51, it 153751 >> 25.03 (41.478 sec) : loss = 0.05932
INFO: epoch 51, it 154502 >> 50.07 (82.982 sec) : loss = 0.09680
INFO: epoch 51, it 155253 >> 75.10 (124.524 sec) : loss = 0.13550
INFO: epoch 51  >> 100.00 (165.740 sec) : lr 0.0230, train loss 0.09071
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.6
INFO: test : error = 6.6994
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 52, it 156751 >> 25.03 (41.505 sec) : loss = 0.05559
INFO: epoch 52, it 157502 >> 50.07 (82.968 sec) : loss = 0.07445
INFO: epoch 52, it 158253 >> 75.10 (124.452 sec) : loss = 0.06915
INFO: epoch 52  >> 100.00 (165.585 sec) : lr 0.0211, train loss 0.08740
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.4
INFO: test : error = 6.2462
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 53, it 159751 >> 25.03 (41.516 sec) : loss = 0.09638
INFO: epoch 53, it 160502 >> 50.07 (83.106 sec) : loss = 0.10553
INFO: epoch 53, it 161253 >> 75.10 (124.644 sec) : loss = 0.07458
INFO: epoch 53  >> 100.00 (165.817 sec) : lr 0.0192, train loss 0.08517
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.9
INFO: test : error = 7.1374
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 54, it 162751 >> 25.03 (41.562 sec) : loss = 0.06232
INFO: epoch 54, it 163502 >> 50.07 (83.102 sec) : loss = 0.05784
INFO: epoch 54, it 164253 >> 75.10 (124.581 sec) : loss = 0.09075
INFO: epoch 54  >> 100.00 (165.695 sec) : lr 0.0173, train loss 0.08228
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.2
INFO: test : error = 6.7379
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 55, it 165751 >> 25.03 (41.435 sec) : loss = 0.10860
INFO: epoch 55, it 166502 >> 50.07 (82.987 sec) : loss = 0.05232
INFO: epoch 55, it 167253 >> 75.10 (124.497 sec) : loss = 0.13166
INFO: epoch 55  >> 100.00 (165.668 sec) : lr 0.0154, train loss 0.07885
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.3
INFO: test : error = 7.3294
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 56, it 168751 >> 25.03 (41.458 sec) : loss = 0.06488
INFO: epoch 56, it 169502 >> 50.07 (82.997 sec) : loss = 0.08199
INFO: epoch 56, it 170253 >> 75.10 (124.422 sec) : loss = 0.05821
INFO: epoch 56  >> 100.00 (165.561 sec) : lr 0.0137, train loss 0.07524
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.5
INFO: test : error = 6.8531
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 57, it 171751 >> 25.03 (41.548 sec) : loss = 0.11857
INFO: epoch 57, it 172502 >> 50.07 (83.137 sec) : loss = 0.09251
INFO: epoch 57, it 173253 >> 75.10 (124.604 sec) : loss = 0.06886
INFO: epoch 57  >> 100.00 (165.793 sec) : lr 0.0119, train loss 0.07285
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.9
INFO: test : error = 5.8313
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 58, it 174751 >> 25.03 (41.480 sec) : loss = 0.02885
INFO: epoch 58, it 175502 >> 50.07 (83.012 sec) : loss = 0.08321
INFO: epoch 58, it 176253 >> 75.10 (124.430 sec) : loss = 0.05648
INFO: epoch 58  >> 100.00 (165.587 sec) : lr 0.0103, train loss 0.06903
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.5
INFO: test : error = 6.3115
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 59, it 177751 >> 25.03 (41.536 sec) : loss = 0.06704
INFO: epoch 59, it 178502 >> 50.07 (83.195 sec) : loss = 0.04914
INFO: epoch 59, it 179253 >> 75.10 (124.746 sec) : loss = 0.06171
INFO: epoch 59  >> 100.00 (165.932 sec) : lr 0.0088, train loss 0.06547
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.0
INFO: test : error = 5.4779
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 60, it 180751 >> 25.03 (41.562 sec) : loss = 0.05119
INFO: epoch 60, it 181502 >> 50.07 (83.122 sec) : loss = 0.02522
INFO: epoch 60, it 182253 >> 75.10 (124.509 sec) : loss = 0.08161
INFO: epoch 60  >> 100.00 (165.617 sec) : lr 0.0073, train loss 0.06330
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.7
INFO: test : error = 4.6366
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 61, it 183751 >> 25.03 (41.509 sec) : loss = 0.09389
INFO: epoch 61, it 184502 >> 50.07 (83.036 sec) : loss = 0.03880
INFO: epoch 61, it 185253 >> 75.10 (124.525 sec) : loss = 0.06329
INFO: epoch 61  >> 100.00 (165.695 sec) : lr 0.0060, train loss 0.05921
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.2
INFO: test : error = 5.1129
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 62, it 186751 >> 25.03 (41.529 sec) : loss = 0.03037
INFO: epoch 62, it 187502 >> 50.07 (83.012 sec) : loss = 0.06491
INFO: epoch 62, it 188253 >> 75.10 (124.418 sec) : loss = 0.03386
INFO: epoch 62  >> 100.00 (165.551 sec) : lr 0.0048, train loss 0.05640
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.7
INFO: test : error = 5.04
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 63, it 189751 >> 25.03 (41.607 sec) : loss = 0.09416
INFO: epoch 63, it 190502 >> 50.07 (83.151 sec) : loss = 0.04064
INFO: epoch 63, it 191253 >> 75.10 (124.612 sec) : loss = 0.02464
INFO: epoch 63  >> 100.00 (165.813 sec) : lr 0.0037, train loss 0.05307
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.0
INFO: test : error = 4.99
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 64, it 192751 >> 25.03 (41.565 sec) : loss = 0.05136
INFO: epoch 64, it 193502 >> 50.07 (83.058 sec) : loss = 0.05502
INFO: epoch 64, it 194253 >> 75.10 (124.500 sec) : loss = 0.04985
INFO: epoch 64  >> 100.00 (165.693 sec) : lr 0.0027, train loss 0.04915
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.1
INFO: test : error = 4.3523
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 65, it 195751 >> 25.03 (41.670 sec) : loss = 0.02594
INFO: epoch 65, it 196502 >> 50.07 (83.253 sec) : loss = 0.02118
INFO: epoch 65, it 197253 >> 75.10 (124.691 sec) : loss = 0.02026
INFO: epoch 65  >> 100.00 (165.778 sec) : lr 0.0019, train loss 0.04529
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.6
INFO: test : error = 4.3139
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 66, it 198751 >> 25.03 (41.499 sec) : loss = 0.02353
INFO: epoch 66, it 199502 >> 50.07 (82.978 sec) : loss = 0.06210
INFO: epoch 66, it 200253 >> 75.10 (124.430 sec) : loss = 0.02815
INFO: epoch 66  >> 100.00 (165.629 sec) : lr 0.0012, train loss 0.04315
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.4
INFO: test : error = 4.4215
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 67, it 201751 >> 25.03 (41.539 sec) : loss = 0.03970
INFO: epoch 67, it 202502 >> 50.07 (83.053 sec) : loss = 0.03089
INFO: epoch 67, it 203253 >> 75.10 (124.453 sec) : loss = 0.06204
INFO: epoch 67  >> 100.00 (165.559 sec) : lr 0.0007, train loss 0.04060
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.8
INFO: test : error = 4.4292
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 68, it 204751 >> 25.03 (41.482 sec) : loss = 0.03701
INFO: epoch 68, it 205502 >> 50.07 (82.961 sec) : loss = 0.05389
INFO: epoch 68, it 206253 >> 75.10 (124.398 sec) : loss = 0.05167
INFO: epoch 68  >> 100.00 (165.552 sec) : lr 0.0003, train loss 0.03932
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.7
INFO: test : error = 4.287
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 69, it 207751 >> 25.03 (41.601 sec) : loss = 0.04506
INFO: epoch 69, it 208502 >> 50.07 (83.125 sec) : loss = 0.03883
INFO: epoch 69, it 209253 >> 75.10 (124.586 sec) : loss = 0.05452
INFO: epoch 69  >> 100.00 (165.760 sec) : lr 0.0001, train loss 0.03908
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.9
INFO: test : error = 4.3754
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 70, it 210751 >> 25.03 (41.555 sec) : loss = 0.12762
INFO: epoch 70, it 211502 >> 50.07 (82.936 sec) : loss = 0.15135
INFO: epoch 70, it 212253 >> 75.10 (124.309 sec) : loss = 0.07983
INFO: epoch 70  >> 100.00 (165.601 sec) : lr 0.0500, train loss 0.20694
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.4
INFO: test : error = 8.1592
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 71, it 213751 >> 25.03 (41.845 sec) : loss = 0.15281
INFO: epoch 71, it 214502 >> 50.07 (83.537 sec) : loss = 0.15149
INFO: epoch 71, it 215253 >> 75.10 (125.193 sec) : loss = 0.12859
INFO: epoch 71  >> 100.00 (166.499 sec) : lr 0.0500, train loss 0.13492
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.4
INFO: test : error = 8.3244
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 72, it 216751 >> 25.03 (41.779 sec) : loss = 0.17088
INFO: epoch 72, it 217502 >> 50.07 (83.377 sec) : loss = 0.11960
INFO: epoch 72, it 218253 >> 75.10 (124.998 sec) : loss = 0.11472
INFO: epoch 72  >> 100.00 (166.349 sec) : lr 0.0499, train loss 0.13137
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.6
INFO: test : error = 8.5164
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 73, it 219751 >> 25.03 (41.832 sec) : loss = 0.07909
INFO: epoch 73, it 220502 >> 50.07 (83.478 sec) : loss = 0.10034
INFO: epoch 73, it 221253 >> 75.10 (125.083 sec) : loss = 0.08978
INFO: epoch 73  >> 100.00 (166.392 sec) : lr 0.0498, train loss 0.12847
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.2
INFO: test : error = 7.5023
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 74, it 222751 >> 25.03 (41.759 sec) : loss = 0.14665
INFO: epoch 74, it 223502 >> 50.07 (83.420 sec) : loss = 0.16658
INFO: epoch 74, it 224253 >> 75.10 (125.101 sec) : loss = 0.13589
INFO: epoch 74  >> 100.00 (166.532 sec) : lr 0.0497, train loss 0.12633
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.2
INFO: test : error = 7.291
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 75, it 225751 >> 25.03 (41.723 sec) : loss = 0.08840
INFO: epoch 75, it 226502 >> 50.07 (83.384 sec) : loss = 0.10584
INFO: epoch 75, it 227253 >> 75.10 (124.920 sec) : loss = 0.08539
INFO: epoch 75  >> 100.00 (166.092 sec) : lr 0.0495, train loss 0.12651
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.3
INFO: test : error = 8.6547
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 76, it 228751 >> 25.03 (41.513 sec) : loss = 0.10934
INFO: epoch 76, it 229502 >> 50.07 (82.918 sec) : loss = 0.15620
INFO: epoch 76, it 230253 >> 75.10 (124.346 sec) : loss = 0.17380
INFO: epoch 76  >> 100.00 (165.579 sec) : lr 0.0493, train loss 0.12561
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.4
INFO: test : error = 8.9889
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 77, it 231751 >> 25.03 (41.652 sec) : loss = 0.10207
INFO: epoch 77, it 232502 >> 50.07 (83.108 sec) : loss = 0.11629
INFO: epoch 77, it 233253 >> 75.10 (124.551 sec) : loss = 0.21673
INFO: epoch 77  >> 100.00 (165.748 sec) : lr 0.0491, train loss 0.12416
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.0
INFO: test : error = 8.4281
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 78, it 234751 >> 25.03 (41.542 sec) : loss = 0.06778
INFO: epoch 78, it 235502 >> 50.07 (83.008 sec) : loss = 0.08304
INFO: epoch 78, it 236253 >> 75.10 (124.524 sec) : loss = 0.12192
INFO: epoch 78  >> 100.00 (165.774 sec) : lr 0.0488, train loss 0.12558
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 10.6
INFO: test : error = 9.3078
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 79, it 237751 >> 25.03 (41.595 sec) : loss = 0.12163
INFO: epoch 79, it 238502 >> 50.07 (83.118 sec) : loss = 0.12030
INFO: epoch 79, it 239253 >> 75.10 (124.571 sec) : loss = 0.12555
INFO: epoch 79  >> 100.00 (165.795 sec) : lr 0.0485, train loss 0.12331
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.9
INFO: test : error = 8.3513
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 80, it 240751 >> 25.03 (41.536 sec) : loss = 0.14321
INFO: epoch 80, it 241502 >> 50.07 (82.974 sec) : loss = 0.15362
INFO: epoch 80, it 242253 >> 75.10 (124.429 sec) : loss = 0.15932
INFO: epoch 80  >> 100.00 (165.661 sec) : lr 0.0481, train loss 0.12450
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 9.0
INFO: test : error = 8.0132
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 81, it 243751 >> 25.03 (41.579 sec) : loss = 0.21434
INFO: epoch 81, it 244502 >> 50.07 (82.997 sec) : loss = 0.13637
INFO: epoch 81, it 245253 >> 75.10 (124.400 sec) : loss = 0.14538
INFO: epoch 81  >> 100.00 (165.572 sec) : lr 0.0477, train loss 0.12263
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.3
INFO: test : error = 9.0005
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 82, it 246751 >> 25.03 (41.585 sec) : loss = 0.12908
INFO: epoch 82, it 247502 >> 50.07 (83.091 sec) : loss = 0.08895
INFO: epoch 82, it 248253 >> 75.10 (124.620 sec) : loss = 0.10277
INFO: epoch 82  >> 100.00 (165.818 sec) : lr 0.0473, train loss 0.11947
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.4
INFO: test : error = 8.213
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 83, it 249751 >> 25.03 (41.542 sec) : loss = 0.17383
INFO: epoch 83, it 250502 >> 50.07 (82.990 sec) : loss = 0.11548
INFO: epoch 83, it 251253 >> 75.10 (124.435 sec) : loss = 0.08221
INFO: epoch 83  >> 100.00 (165.674 sec) : lr 0.0468, train loss 0.12173
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.8
INFO: test : error = 9.2886
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 84, it 252751 >> 25.03 (41.614 sec) : loss = 0.15294
INFO: epoch 84, it 253502 >> 50.07 (83.121 sec) : loss = 0.14893
INFO: epoch 84, it 254253 >> 75.10 (124.599 sec) : loss = 0.15022
INFO: epoch 84  >> 100.00 (165.905 sec) : lr 0.0463, train loss 0.11964
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.3
INFO: test : error = 7.9249
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 85, it 255751 >> 25.03 (41.540 sec) : loss = 0.10673
INFO: epoch 85, it 256502 >> 50.07 (82.985 sec) : loss = 0.16123
INFO: epoch 85, it 257253 >> 75.10 (124.400 sec) : loss = 0.18662
INFO: epoch 85  >> 100.00 (165.564 sec) : lr 0.0458, train loss 0.11865
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.3
INFO: test : error = 7.2718
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 86, it 258751 >> 25.03 (41.451 sec) : loss = 0.12457
INFO: epoch 86, it 259502 >> 50.07 (82.929 sec) : loss = 0.11848
INFO: epoch 86, it 260253 >> 75.10 (124.449 sec) : loss = 0.06678
INFO: epoch 86  >> 100.00 (165.726 sec) : lr 0.0452, train loss 0.11889
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.2
INFO: test : error = 7.7251
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 87, it 261751 >> 25.03 (41.427 sec) : loss = 0.07116
INFO: epoch 87, it 262502 >> 50.07 (82.815 sec) : loss = 0.10942
INFO: epoch 87, it 263253 >> 75.10 (124.333 sec) : loss = 0.12402
INFO: epoch 87  >> 100.00 (165.580 sec) : lr 0.0446, train loss 0.11702
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.7
INFO: test : error = 7.46
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 88, it 264751 >> 25.03 (41.575 sec) : loss = 0.14555
INFO: epoch 88, it 265502 >> 50.07 (83.035 sec) : loss = 0.11425
INFO: epoch 88, it 266253 >> 75.10 (124.505 sec) : loss = 0.07720
INFO: epoch 88  >> 100.00 (165.661 sec) : lr 0.0440, train loss 0.11561
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.2
INFO: test : error = 7.3679
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 89, it 267751 >> 25.03 (41.489 sec) : loss = 0.16373
INFO: epoch 89, it 268502 >> 50.07 (82.968 sec) : loss = 0.27536
INFO: epoch 89, it 269253 >> 75.10 (124.562 sec) : loss = 0.10827
INFO: epoch 89  >> 100.00 (165.871 sec) : lr 0.0434, train loss 0.11571
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.0
INFO: test : error = 7.4562
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 90, it 270751 >> 25.03 (41.472 sec) : loss = 0.10574
INFO: epoch 90, it 271502 >> 50.07 (82.927 sec) : loss = 0.06756
INFO: epoch 90, it 272253 >> 75.10 (124.490 sec) : loss = 0.07733
INFO: epoch 90  >> 100.00 (165.698 sec) : lr 0.0427, train loss 0.11558
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.5
INFO: test : error = 8.1093
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 91, it 273751 >> 25.03 (41.463 sec) : loss = 0.20977
INFO: epoch 91, it 274502 >> 50.07 (82.867 sec) : loss = 0.11154
INFO: epoch 91, it 275253 >> 75.10 (124.357 sec) : loss = 0.21787
INFO: epoch 91  >> 100.00 (165.576 sec) : lr 0.0420, train loss 0.11497
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.9
INFO: test : error = 8.1131
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 92, it 276751 >> 25.03 (41.535 sec) : loss = 0.10953
INFO: epoch 92, it 277502 >> 50.07 (83.003 sec) : loss = 0.08056
INFO: epoch 92, it 278253 >> 75.10 (124.514 sec) : loss = 0.14360
INFO: epoch 92  >> 100.00 (165.756 sec) : lr 0.0412, train loss 0.11377
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.3
INFO: test : error = 7.6444
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 93, it 279751 >> 25.03 (41.502 sec) : loss = 0.16250
INFO: epoch 93, it 280502 >> 50.07 (82.898 sec) : loss = 0.16857
INFO: epoch 93, it 281253 >> 75.10 (124.331 sec) : loss = 0.08009
INFO: epoch 93  >> 100.00 (165.493 sec) : lr 0.0405, train loss 0.11095
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 8.2
INFO: test : error = 7.3448
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 94, it 282751 >> 25.03 (41.427 sec) : loss = 0.16738
INFO: epoch 94, it 283502 >> 50.07 (82.868 sec) : loss = 0.10336
INFO: epoch 94, it 284253 >> 75.10 (124.430 sec) : loss = 0.09097
INFO: epoch 94  >> 100.00 (165.674 sec) : lr 0.0397, train loss 0.11200
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.6
INFO: test : error = 8.3167
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 95, it 285751 >> 25.03 (41.496 sec) : loss = 0.09585
INFO: epoch 95, it 286502 >> 50.07 (82.967 sec) : loss = 0.06798
INFO: epoch 95, it 287253 >> 75.10 (124.434 sec) : loss = 0.08569
INFO: epoch 95  >> 100.00 (165.588 sec) : lr 0.0389, train loss 0.10935
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.7
INFO: test : error = 6.4997
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 96, it 288751 >> 25.03 (41.432 sec) : loss = 0.07872
INFO: epoch 96, it 289502 >> 50.07 (82.822 sec) : loss = 0.11118
INFO: epoch 96, it 290253 >> 75.10 (124.283 sec) : loss = 0.12018
INFO: epoch 96  >> 100.00 (165.509 sec) : lr 0.0381, train loss 0.10861
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.4
INFO: test : error = 7.8288
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 97, it 291751 >> 25.03 (41.568 sec) : loss = 0.14942
INFO: epoch 97, it 292502 >> 50.07 (83.046 sec) : loss = 0.11663
INFO: epoch 97, it 293253 >> 75.10 (124.536 sec) : loss = 0.09131
INFO: epoch 97  >> 100.00 (165.707 sec) : lr 0.0372, train loss 0.10674
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.9
INFO: test : error = 7.4677
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 98, it 294751 >> 25.03 (41.445 sec) : loss = 0.07712
INFO: epoch 98, it 295502 >> 50.07 (82.877 sec) : loss = 0.07193
INFO: epoch 98, it 296253 >> 75.10 (124.410 sec) : loss = 0.10807
INFO: epoch 98  >> 100.00 (165.668 sec) : lr 0.0363, train loss 0.10732
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.5
INFO: test : error = 6.9299
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 99, it 297751 >> 25.03 (41.459 sec) : loss = 0.11384
INFO: epoch 99, it 298502 >> 50.07 (82.870 sec) : loss = 0.06618
INFO: epoch 99, it 299253 >> 75.10 (124.316 sec) : loss = 0.11211
INFO: epoch 99  >> 100.00 (165.481 sec) : lr 0.0355, train loss 0.10609
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.1
INFO: test : error = 8.1208
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 100, it 300751 >> 25.03 (41.500 sec) : loss = 0.11317
INFO: epoch 100, it 301502 >> 50.07 (83.069 sec) : loss = 0.16364
INFO: epoch 100, it 302253 >> 75.10 (124.556 sec) : loss = 0.08126
INFO: epoch 100  >> 100.00 (165.725 sec) : lr 0.0346, train loss 0.10492
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.9
INFO: test : error = 7.3218
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 101, it 303751 >> 25.03 (41.505 sec) : loss = 0.05187
INFO: epoch 101, it 304502 >> 50.07 (82.987 sec) : loss = 0.12609
INFO: epoch 101, it 305253 >> 75.10 (124.446 sec) : loss = 0.10285
INFO: epoch 101  >> 100.00 (165.531 sec) : lr 0.0337, train loss 0.10331
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.8
INFO: test : error = 6.7417
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 102, it 306751 >> 25.03 (41.434 sec) : loss = 0.08818
INFO: epoch 102, it 307502 >> 50.07 (82.924 sec) : loss = 0.12534
INFO: epoch 102, it 308253 >> 75.10 (124.442 sec) : loss = 0.07485
INFO: epoch 102  >> 100.00 (165.614 sec) : lr 0.0327, train loss 0.10473
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.6
INFO: test : error = 6.4536
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 103, it 309751 >> 25.03 (41.467 sec) : loss = 0.07976
INFO: epoch 103, it 310502 >> 50.07 (82.954 sec) : loss = 0.05991
INFO: epoch 103, it 311253 >> 75.10 (124.459 sec) : loss = 0.08379
INFO: epoch 103  >> 100.00 (165.539 sec) : lr 0.0318, train loss 0.10109
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.9
INFO: test : error = 7.1681
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 104, it 312751 >> 25.03 (41.390 sec) : loss = 0.07980
INFO: epoch 104, it 313502 >> 50.07 (82.841 sec) : loss = 0.15590
INFO: epoch 104, it 314253 >> 75.10 (124.343 sec) : loss = 0.09438
INFO: epoch 104  >> 100.00 (165.459 sec) : lr 0.0308, train loss 0.10042
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.8
INFO: test : error = 7.5484
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 105, it 315751 >> 25.03 (41.513 sec) : loss = 0.07204
INFO: epoch 105, it 316502 >> 50.07 (83.043 sec) : loss = 0.13256
INFO: epoch 105, it 317253 >> 75.10 (124.547 sec) : loss = 0.03591
INFO: epoch 105  >> 100.00 (165.695 sec) : lr 0.0299, train loss 0.09964
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 7.6214
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 106, it 318751 >> 25.03 (41.512 sec) : loss = 0.08105
INFO: epoch 106, it 319502 >> 50.07 (82.994 sec) : loss = 0.13405
INFO: epoch 106, it 320253 >> 75.10 (124.453 sec) : loss = 0.08087
INFO: epoch 106  >> 100.00 (165.512 sec) : lr 0.0289, train loss 0.09807
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.2
INFO: test : error = 6.7686
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 107, it 321751 >> 25.03 (41.424 sec) : loss = 0.07274
INFO: epoch 107, it 322502 >> 50.07 (82.926 sec) : loss = 0.07909
INFO: epoch 107, it 323253 >> 75.10 (124.463 sec) : loss = 0.06391
INFO: epoch 107  >> 100.00 (165.652 sec) : lr 0.0279, train loss 0.09758
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.6
INFO: test : error = 6.638
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 108, it 324751 >> 25.03 (41.518 sec) : loss = 0.07735
INFO: epoch 108, it 325502 >> 50.07 (83.059 sec) : loss = 0.11425
INFO: epoch 108, it 326253 >> 75.10 (124.556 sec) : loss = 0.12151
INFO: epoch 108  >> 100.00 (165.656 sec) : lr 0.0270, train loss 0.09727
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.8
INFO: test : error = 6.5612
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 109, it 327751 >> 25.03 (41.416 sec) : loss = 0.10819
INFO: epoch 109, it 328502 >> 50.07 (82.853 sec) : loss = 0.07625
INFO: epoch 109, it 329253 >> 75.10 (124.312 sec) : loss = 0.15015
INFO: epoch 109  >> 100.00 (165.431 sec) : lr 0.0260, train loss 0.09408
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.4
INFO: test : error = 6.4959
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 110, it 330751 >> 25.03 (41.534 sec) : loss = 0.09420
INFO: epoch 110, it 331502 >> 50.07 (83.066 sec) : loss = 0.11854
INFO: epoch 110, it 332253 >> 75.10 (124.542 sec) : loss = 0.11620
INFO: epoch 110  >> 100.00 (165.647 sec) : lr 0.0250, train loss 0.09335
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.1
INFO: test : error = 6.8339
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 111, it 333751 >> 25.03 (41.448 sec) : loss = 0.06492
INFO: epoch 111, it 334502 >> 50.07 (82.967 sec) : loss = 0.10380
INFO: epoch 111, it 335253 >> 75.10 (124.562 sec) : loss = 0.09980
INFO: epoch 111  >> 100.00 (165.770 sec) : lr 0.0240, train loss 0.09136
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.7
INFO: test : error = 6.6265
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 112, it 336751 >> 25.03 (41.515 sec) : loss = 0.06321
INFO: epoch 112, it 337502 >> 50.07 (82.938 sec) : loss = 0.08734
INFO: epoch 112, it 338253 >> 75.10 (124.393 sec) : loss = 0.03258
INFO: epoch 112  >> 100.00 (165.505 sec) : lr 0.0230, train loss 0.09206
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.9
INFO: test : error = 6.5151
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 113, it 339751 >> 25.03 (41.517 sec) : loss = 0.09462
INFO: epoch 113, it 340502 >> 50.07 (82.962 sec) : loss = 0.07800
INFO: epoch 113, it 341253 >> 75.10 (124.509 sec) : loss = 0.07075
INFO: epoch 113  >> 100.00 (165.658 sec) : lr 0.0221, train loss 0.08906
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.1
INFO: test : error = 7.268
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 114, it 342751 >> 25.03 (41.581 sec) : loss = 0.11692
INFO: epoch 114, it 343502 >> 50.07 (83.065 sec) : loss = 0.07717
INFO: epoch 114, it 344253 >> 75.10 (124.547 sec) : loss = 0.05301
INFO: epoch 114  >> 100.00 (165.661 sec) : lr 0.0211, train loss 0.08769
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.4
INFO: test : error = 6.3038
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 115, it 345751 >> 25.03 (41.515 sec) : loss = 0.06314
INFO: epoch 115, it 346502 >> 50.07 (82.993 sec) : loss = 0.11742
INFO: epoch 115, it 347253 >> 75.10 (124.453 sec) : loss = 0.10549
INFO: epoch 115  >> 100.00 (165.666 sec) : lr 0.0201, train loss 0.08595
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.4
INFO: test : error = 6.807
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 116, it 348751 >> 25.03 (41.597 sec) : loss = 0.11191
INFO: epoch 116, it 349502 >> 50.07 (83.112 sec) : loss = 0.05252
INFO: epoch 116, it 350253 >> 75.10 (124.582 sec) : loss = 0.11653
INFO: epoch 116  >> 100.00 (165.785 sec) : lr 0.0192, train loss 0.08669
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.2
INFO: test : error = 6.734
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 117, it 351751 >> 25.03 (41.539 sec) : loss = 0.08779
INFO: epoch 117, it 352502 >> 50.07 (83.007 sec) : loss = 0.05454
INFO: epoch 117, it 353253 >> 75.10 (124.400 sec) : loss = 0.09058
INFO: epoch 117  >> 100.00 (165.541 sec) : lr 0.0182, train loss 0.08224
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.1
INFO: test : error = 5.9926
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 118, it 354751 >> 25.03 (41.537 sec) : loss = 0.07213
INFO: epoch 118, it 355502 >> 50.07 (83.064 sec) : loss = 0.15961
INFO: epoch 118, it 356253 >> 75.10 (124.522 sec) : loss = 0.06882
INFO: epoch 118  >> 100.00 (165.598 sec) : lr 0.0173, train loss 0.08357
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.4
INFO: test : error = 6.1885
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 119, it 357751 >> 25.03 (41.514 sec) : loss = 0.06340
INFO: epoch 119, it 358502 >> 50.07 (83.011 sec) : loss = 0.07083
INFO: epoch 119, it 359253 >> 75.10 (124.467 sec) : loss = 0.07120
INFO: epoch 119  >> 100.00 (165.643 sec) : lr 0.0163, train loss 0.08210
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.0
INFO: test : error = 6.2231
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 120, it 360751 >> 25.03 (41.573 sec) : loss = 0.10331
INFO: epoch 120, it 361502 >> 50.07 (83.077 sec) : loss = 0.12423
INFO: epoch 120, it 362253 >> 75.10 (124.456 sec) : loss = 0.05496
INFO: epoch 120  >> 100.00 (165.527 sec) : lr 0.0154, train loss 0.07966
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.0
INFO: test : error = 7.0797
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 121, it 363751 >> 25.03 (41.515 sec) : loss = 0.06464
INFO: epoch 121, it 364502 >> 50.07 (83.023 sec) : loss = 0.09084
INFO: epoch 121, it 365253 >> 75.10 (124.509 sec) : loss = 0.07346
INFO: epoch 121  >> 100.00 (165.758 sec) : lr 0.0145, train loss 0.07745
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.5
INFO: test : error = 6.419
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 122, it 366751 >> 25.03 (41.543 sec) : loss = 0.08483
INFO: epoch 122, it 367502 >> 50.07 (82.995 sec) : loss = 0.07510
INFO: epoch 122, it 368253 >> 75.10 (124.365 sec) : loss = 0.07798
INFO: epoch 122  >> 100.00 (165.477 sec) : lr 0.0137, train loss 0.07657
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.5
INFO: test : error = 5.8044
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 123, it 369751 >> 25.03 (41.509 sec) : loss = 0.13370
INFO: epoch 123, it 370502 >> 50.07 (83.027 sec) : loss = 0.05992
INFO: epoch 123, it 371253 >> 75.10 (124.557 sec) : loss = 0.09434
INFO: epoch 123  >> 100.00 (165.743 sec) : lr 0.0128, train loss 0.07420
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 7.0
INFO: test : error = 6.3422
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 124, it 372751 >> 25.03 (41.498 sec) : loss = 0.06743
INFO: epoch 124, it 373502 >> 50.07 (82.915 sec) : loss = 0.11320
INFO: epoch 124, it 374253 >> 75.10 (124.271 sec) : loss = 0.04144
INFO: epoch 124  >> 100.00 (165.400 sec) : lr 0.0119, train loss 0.07309
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.7
INFO: test : error = 5.5893
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 125, it 375751 >> 25.03 (41.483 sec) : loss = 0.13456
INFO: epoch 125, it 376502 >> 50.07 (83.013 sec) : loss = 0.09509
INFO: epoch 125, it 377253 >> 75.10 (124.418 sec) : loss = 0.07669
INFO: epoch 125  >> 100.00 (165.517 sec) : lr 0.0111, train loss 0.07230
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.5
INFO: test : error = 5.8351
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 126, it 378751 >> 25.03 (41.393 sec) : loss = 0.04262
INFO: epoch 126, it 379502 >> 50.07 (82.817 sec) : loss = 0.04646
INFO: epoch 126, it 380253 >> 75.10 (124.208 sec) : loss = 0.05643
INFO: epoch 126  >> 100.00 (165.406 sec) : lr 0.0103, train loss 0.07067
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.9
INFO: test : error = 5.3434
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 127, it 381751 >> 25.03 (41.517 sec) : loss = 0.07642
INFO: epoch 127, it 382502 >> 50.07 (83.025 sec) : loss = 0.06868
INFO: epoch 127, it 383253 >> 75.10 (124.485 sec) : loss = 0.05395
INFO: epoch 127  >> 100.00 (165.727 sec) : lr 0.0095, train loss 0.06873
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.5
INFO: test : error = 6.0579
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 128, it 384751 >> 25.03 (41.426 sec) : loss = 0.05939
INFO: epoch 128, it 385502 >> 50.07 (82.851 sec) : loss = 0.06520
INFO: epoch 128, it 386253 >> 75.10 (124.215 sec) : loss = 0.06086
INFO: epoch 128  >> 100.00 (165.360 sec) : lr 0.0088, train loss 0.06751
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 6.0
INFO: test : error = 5.7852
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 129, it 387751 >> 25.03 (41.513 sec) : loss = 0.02141
INFO: epoch 129, it 388502 >> 50.07 (83.041 sec) : loss = 0.04813
INFO: epoch 129, it 389253 >> 75.10 (124.506 sec) : loss = 0.08339
INFO: epoch 129  >> 100.00 (165.694 sec) : lr 0.0080, train loss 0.06545
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.0
INFO: test : error = 5.4356
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 130, it 390751 >> 25.03 (41.450 sec) : loss = 0.03874
INFO: epoch 130, it 391502 >> 50.07 (82.849 sec) : loss = 0.04982
INFO: epoch 130, it 392253 >> 75.10 (124.259 sec) : loss = 0.04497
INFO: epoch 130  >> 100.00 (165.457 sec) : lr 0.0073, train loss 0.06456
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.9
INFO: test : error = 5.4356
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 131, it 393751 >> 25.03 (41.566 sec) : loss = 0.10780
INFO: epoch 131, it 394502 >> 50.07 (83.011 sec) : loss = 0.06843
INFO: epoch 131, it 395253 >> 75.10 (124.438 sec) : loss = 0.10162
INFO: epoch 131  >> 100.00 (165.639 sec) : lr 0.0066, train loss 0.06172
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.6
INFO: test : error = 5.0476
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 132, it 396751 >> 25.03 (41.480 sec) : loss = 0.03087
INFO: epoch 132, it 397502 >> 50.07 (82.863 sec) : loss = 0.04041
INFO: epoch 132, it 398253 >> 75.10 (124.243 sec) : loss = 0.04035
INFO: epoch 132  >> 100.00 (165.388 sec) : lr 0.0060, train loss 0.06000
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.0
INFO: test : error = 5.3127
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 133, it 399751 >> 25.03 (41.519 sec) : loss = 0.05916
INFO: epoch 133, it 400502 >> 50.07 (82.968 sec) : loss = 0.06934
INFO: epoch 133, it 401253 >> 75.10 (124.416 sec) : loss = 0.05219
INFO: epoch 133  >> 100.00 (165.578 sec) : lr 0.0054, train loss 0.05822
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.3
INFO: test : error = 4.7672
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 134, it 402751 >> 25.03 (41.525 sec) : loss = 0.03912
INFO: epoch 134, it 403502 >> 50.07 (82.899 sec) : loss = 0.03657
INFO: epoch 134, it 404253 >> 75.10 (124.273 sec) : loss = 0.06636
INFO: epoch 134  >> 100.00 (165.419 sec) : lr 0.0048, train loss 0.05625
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.5
INFO: test : error = 5.3934
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 135, it 405751 >> 25.03 (41.496 sec) : loss = 0.02295
INFO: epoch 135, it 406502 >> 50.07 (82.894 sec) : loss = 0.05586
INFO: epoch 135, it 407253 >> 75.10 (124.344 sec) : loss = 0.04488
INFO: epoch 135  >> 100.00 (165.505 sec) : lr 0.0042, train loss 0.05467
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.7
INFO: test : error = 4.7749
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 136, it 408751 >> 25.03 (41.492 sec) : loss = 0.04239
INFO: epoch 136, it 409502 >> 50.07 (82.840 sec) : loss = 0.05284
INFO: epoch 136, it 410253 >> 75.10 (124.246 sec) : loss = 0.05688
INFO: epoch 136  >> 100.00 (165.411 sec) : lr 0.0037, train loss 0.05212
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.7
INFO: test : error = 5.0169
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 137, it 411751 >> 25.03 (41.555 sec) : loss = 0.01810
INFO: epoch 137, it 412502 >> 50.07 (82.950 sec) : loss = 0.02320
INFO: epoch 137, it 413253 >> 75.10 (124.341 sec) : loss = 0.05560
INFO: epoch 137  >> 100.00 (165.482 sec) : lr 0.0032, train loss 0.04973
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.4
INFO: test : error = 4.6789
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 138, it 414751 >> 25.03 (41.511 sec) : loss = 0.06342
INFO: epoch 138, it 415502 >> 50.07 (82.957 sec) : loss = 0.03557
INFO: epoch 138, it 416253 >> 75.10 (124.449 sec) : loss = 0.06312
INFO: epoch 138  >> 100.00 (165.566 sec) : lr 0.0027, train loss 0.04776
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.1
INFO: test : error = 4.4791
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 139, it 417751 >> 25.03 (41.479 sec) : loss = 0.04544
INFO: epoch 139, it 418502 >> 50.07 (82.832 sec) : loss = 0.04239
INFO: epoch 139, it 419253 >> 75.10 (124.244 sec) : loss = 0.10520
INFO: epoch 139  >> 100.00 (165.285 sec) : lr 0.0023, train loss 0.04582
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.6
INFO: test : error = 4.287
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 140, it 420751 >> 25.03 (41.464 sec) : loss = 0.02413
INFO: epoch 140, it 421502 >> 50.07 (82.847 sec) : loss = 0.04166
INFO: epoch 140, it 422253 >> 75.10 (124.324 sec) : loss = 0.04433
INFO: epoch 140  >> 100.00 (165.414 sec) : lr 0.0019, train loss 0.04410
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.7
INFO: test : error = 4.5751
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 141, it 423751 >> 25.03 (41.535 sec) : loss = 0.07949
INFO: epoch 141, it 424502 >> 50.07 (82.909 sec) : loss = 0.02312
INFO: epoch 141, it 425253 >> 75.10 (124.348 sec) : loss = 0.02907
INFO: epoch 141  >> 100.00 (165.405 sec) : lr 0.0015, train loss 0.04181
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.0
INFO: test : error = 4.4906
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 142, it 426751 >> 25.03 (41.492 sec) : loss = 0.05432
INFO: epoch 142, it 427502 >> 50.07 (82.868 sec) : loss = 0.04707
INFO: epoch 142, it 428253 >> 75.10 (124.253 sec) : loss = 0.03168
INFO: epoch 142  >> 100.00 (164.933 sec) : lr 0.0012, train loss 0.04042
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.0
INFO: test : error = 4.3831
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 143, it 429751 >> 25.03 (41.061 sec) : loss = 0.02470
INFO: epoch 143, it 430502 >> 50.07 (81.947 sec) : loss = 0.01202
INFO: epoch 143, it 431253 >> 75.10 (122.806 sec) : loss = 0.03200
INFO: epoch 143  >> 100.00 (163.441 sec) : lr 0.0009, train loss 0.03824
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.3
INFO: test : error = 4.2371
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 144, it 432751 >> 25.03 (41.108 sec) : loss = 0.04083
INFO: epoch 144, it 433502 >> 50.07 (81.993 sec) : loss = 0.06833
INFO: epoch 144, it 434253 >> 75.10 (122.933 sec) : loss = 0.01739
INFO: epoch 144  >> 100.00 (163.598 sec) : lr 0.0007, train loss 0.03703
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.0
INFO: test : error = 4.3447
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 145, it 435751 >> 25.03 (40.899 sec) : loss = 0.02737
INFO: epoch 145, it 436502 >> 50.07 (81.700 sec) : loss = 0.02569
INFO: epoch 145, it 437253 >> 75.10 (122.504 sec) : loss = 0.04405
INFO: epoch 145  >> 100.00 (163.075 sec) : lr 0.0005, train loss 0.03477
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.7
INFO: test : error = 4.3754
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 146, it 438751 >> 25.03 (40.858 sec) : loss = 0.01975
INFO: epoch 146, it 439502 >> 50.07 (81.587 sec) : loss = 0.02579
INFO: epoch 146, it 440253 >> 75.10 (122.383 sec) : loss = 0.04808
INFO: epoch 146  >> 100.00 (162.829 sec) : lr 0.0003, train loss 0.03376
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.9
INFO: test : error = 4.1756
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 147, it 441751 >> 25.03 (40.740 sec) : loss = 0.05499
INFO: epoch 147, it 442502 >> 50.07 (81.450 sec) : loss = 0.01762
INFO: epoch 147, it 443253 >> 75.10 (122.206 sec) : loss = 0.02964
INFO: epoch 147  >> 100.00 (162.666 sec) : lr 0.0002, train loss 0.03320
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.9
INFO: test : error = 4.1564
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 148, it 444751 >> 25.03 (40.852 sec) : loss = 0.03579
INFO: epoch 148, it 445502 >> 50.07 (81.741 sec) : loss = 0.03696
INFO: epoch 148, it 446253 >> 75.10 (122.601 sec) : loss = 0.03125
INFO: epoch 148  >> 100.00 (163.063 sec) : lr 0.0001, train loss 0.03273
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.6
INFO: test : error = 4.1219
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 149, it 447751 >> 25.03 (40.849 sec) : loss = 0.03381
INFO: epoch 149, it 448502 >> 50.07 (81.640 sec) : loss = 0.03174
INFO: epoch 149, it 449253 >> 75.10 (122.437 sec) : loss = 0.02953
INFO: epoch 149  >> 100.00 (162.963 sec) : lr 0.0000, train loss 0.03252
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.4
INFO: test : error = 4.1257
INFO: >>>>>>>>>>>>>>BEST PERFORMANCE, epoch 64<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.1
INFO: test : error = 4.3523
