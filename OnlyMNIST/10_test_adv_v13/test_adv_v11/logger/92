INFO: Running with the following configs:
	seed : 0
	device : cuda:0
	data_dir : ../../data/mnist_v13
	domain : mnist_orig
	img_size : 28
	batch_size : 100
	num_epochs : 20
	num_iters_per_epoch : 1000
	optim : sgd
	lr : 0.05
	momentum : 0.9
	l2_params : 0.0005
	max_grad_norm : 1
	scheduler_t0 : 10
	scheduler_tmult : 1
	lenet_depth : 28
	lenet_widen_factor : 1
	lenet_droprate : 0.3
	fc_nlayers : 1
	fc_hidden_dim : 1024
	fc_droprate : 0.3
	model_id : 92
	model_dir : ./saved_models
	eval_set : test_lbl
	ckpt_name : best_model.ckpt
	load : False

INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 0, it 251 >> 25.00 (1.300 sec) : loss = 0.00032
INFO: epoch 0, it 502 >> 50.10 (2.487 sec) : loss = 0.00024
INFO: epoch 0, it 753 >> 75.20 (3.659 sec) : loss = 0.00012
INFO: epoch 0, it 1000 >> 100.00 (4.723 sec) : lr 0.0500, train loss 0.06789
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 12.3
INFO: test : error = 13.24
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 1, it 1251 >> 25.00 (1.092 sec) : loss = 0.00020
INFO: epoch 1, it 1502 >> 50.10 (2.211 sec) : loss = 0.00035
INFO: epoch 1, it 1753 >> 75.20 (3.347 sec) : loss = 0.00068
INFO: epoch 1, it 2000 >> 100.00 (4.357 sec) : lr 0.0488, train loss 0.00042
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 12.9
INFO: test : error = 13.38
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 2, it 2251 >> 25.00 (1.071 sec) : loss = 0.00020
INFO: epoch 2, it 2502 >> 50.10 (2.258 sec) : loss = 0.00019
INFO: epoch 2, it 2753 >> 75.20 (3.399 sec) : loss = 0.00015
INFO: epoch 2, it 3000 >> 100.00 (4.620 sec) : lr 0.0452, train loss 0.00045
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.3
INFO: test : error = 13.56
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 3, it 3251 >> 25.00 (1.110 sec) : loss = 0.00028
INFO: epoch 3, it 3502 >> 50.10 (2.253 sec) : loss = 0.00094
INFO: epoch 3, it 3753 >> 75.20 (3.335 sec) : loss = 0.00015
INFO: epoch 3, it 4000 >> 100.00 (4.450 sec) : lr 0.0397, train loss 0.00049
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.2
INFO: test : error = 13.66
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 4, it 4251 >> 25.00 (1.044 sec) : loss = 0.00040
INFO: epoch 4, it 4502 >> 50.10 (2.113 sec) : loss = 0.00067
INFO: epoch 4, it 4753 >> 75.20 (3.226 sec) : loss = 0.00098
INFO: epoch 4, it 5000 >> 100.00 (4.421 sec) : lr 0.0327, train loss 0.00050
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.5
INFO: test : error = 13.94
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 5, it 5251 >> 25.00 (1.019 sec) : loss = 0.00043
INFO: epoch 5, it 5502 >> 50.10 (2.028 sec) : loss = 0.00048
INFO: epoch 5, it 5753 >> 75.20 (3.175 sec) : loss = 0.00037
INFO: epoch 5, it 6000 >> 100.00 (4.363 sec) : lr 0.0250, train loss 0.00049
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.9
INFO: test : error = 14.17
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 6, it 6251 >> 25.00 (1.164 sec) : loss = 0.00020
INFO: epoch 6, it 6502 >> 50.10 (2.416 sec) : loss = 0.00032
INFO: epoch 6, it 6753 >> 75.20 (3.653 sec) : loss = 0.00025
INFO: epoch 6, it 7000 >> 100.00 (4.770 sec) : lr 0.0173, train loss 0.00048
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.7
INFO: test : error = 14.12
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 7, it 7251 >> 25.00 (1.129 sec) : loss = 0.00024
INFO: epoch 7, it 7502 >> 50.10 (2.261 sec) : loss = 0.00055
INFO: epoch 7, it 7753 >> 75.20 (3.398 sec) : loss = 0.00038
INFO: epoch 7, it 8000 >> 100.00 (4.395 sec) : lr 0.0103, train loss 0.00048
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.7
INFO: test : error = 14.41
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 8, it 8251 >> 25.00 (1.171 sec) : loss = 0.00049
INFO: epoch 8, it 8502 >> 50.10 (2.327 sec) : loss = 0.00040
INFO: epoch 8, it 8753 >> 75.20 (3.527 sec) : loss = 0.00089
INFO: epoch 8, it 9000 >> 100.00 (4.711 sec) : lr 0.0048, train loss 0.00048
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.6
INFO: test : error = 14.3
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 9, it 9251 >> 25.00 (1.259 sec) : loss = 0.00025
INFO: epoch 9, it 9502 >> 50.10 (2.353 sec) : loss = 0.00050
INFO: epoch 9, it 9753 >> 75.20 (3.483 sec) : loss = 0.00068
INFO: epoch 9, it 10000 >> 100.00 (4.609 sec) : lr 0.0012, train loss 0.00048
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 13.8
INFO: test : error = 14.43
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 10, it 10251 >> 25.00 (1.173 sec) : loss = 0.00042
INFO: epoch 10, it 10502 >> 50.10 (2.286 sec) : loss = 0.00028
INFO: epoch 10, it 10753 >> 75.20 (3.455 sec) : loss = 0.00039
INFO: epoch 10, it 11000 >> 100.00 (4.641 sec) : lr 0.0500, train loss 0.00049
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.4
INFO: test : error = 14.44
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 11, it 11251 >> 25.00 (1.125 sec) : loss = 0.00054
INFO: epoch 11, it 11502 >> 50.10 (2.404 sec) : loss = 0.00028
INFO: epoch 11, it 11753 >> 75.20 (3.665 sec) : loss = 0.00079
INFO: epoch 11, it 12000 >> 100.00 (4.718 sec) : lr 0.0488, train loss 0.00046
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.0
INFO: test : error = 14.73
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 12, it 12251 >> 25.00 (1.116 sec) : loss = 0.00047
INFO: epoch 12, it 12502 >> 50.10 (2.224 sec) : loss = 0.00048
INFO: epoch 12, it 12753 >> 75.20 (3.299 sec) : loss = 0.00075
INFO: epoch 12, it 13000 >> 100.00 (4.475 sec) : lr 0.0452, train loss 0.00046
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.7
INFO: test : error = 15.14
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 13, it 13251 >> 25.00 (1.176 sec) : loss = 0.00052
INFO: epoch 13, it 13502 >> 50.10 (2.307 sec) : loss = 0.00053
INFO: epoch 13, it 13753 >> 75.20 (3.495 sec) : loss = 0.00027
INFO: epoch 13, it 14000 >> 100.00 (4.642 sec) : lr 0.0397, train loss 0.00045
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.6
INFO: test : error = 14.97
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 14, it 14251 >> 25.00 (1.221 sec) : loss = 0.00029
INFO: epoch 14, it 14502 >> 50.10 (2.439 sec) : loss = 0.00022
INFO: epoch 14, it 14753 >> 75.20 (3.664 sec) : loss = 0.00043
INFO: epoch 14, it 15000 >> 100.00 (4.719 sec) : lr 0.0327, train loss 0.00044
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.7
INFO: test : error = 15.19
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 15, it 15251 >> 25.00 (1.140 sec) : loss = 0.00045
INFO: epoch 15, it 15502 >> 50.10 (2.315 sec) : loss = 0.00058
INFO: epoch 15, it 15753 >> 75.20 (3.369 sec) : loss = 0.00113
INFO: epoch 15, it 16000 >> 100.00 (4.421 sec) : lr 0.0250, train loss 0.00043
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.7
INFO: test : error = 15.23
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 16, it 16251 >> 25.00 (1.104 sec) : loss = 0.00014
INFO: epoch 16, it 16502 >> 50.10 (2.076 sec) : loss = 0.00062
INFO: epoch 16, it 16753 >> 75.20 (3.121 sec) : loss = 0.00028
INFO: epoch 16, it 17000 >> 100.00 (4.149 sec) : lr 0.0173, train loss 0.00042
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.8
INFO: test : error = 15.15
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 17, it 17251 >> 25.00 (1.341 sec) : loss = 0.00075
INFO: epoch 17, it 17502 >> 50.10 (2.628 sec) : loss = 0.00035
INFO: epoch 17, it 17753 >> 75.20 (3.752 sec) : loss = 0.00046
INFO: epoch 17, it 18000 >> 100.00 (4.815 sec) : lr 0.0103, train loss 0.00042
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 15.0
INFO: test : error = 15.33
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 18, it 18251 >> 25.00 (1.140 sec) : loss = 0.00037
INFO: epoch 18, it 18502 >> 50.10 (2.357 sec) : loss = 0.00034
INFO: epoch 18, it 18753 >> 75.20 (3.623 sec) : loss = 0.00040
INFO: epoch 18, it 19000 >> 100.00 (4.874 sec) : lr 0.0048, train loss 0.00041
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 15.1
INFO: test : error = 15.39
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 19, it 19251 >> 25.00 (1.127 sec) : loss = 0.00031
INFO: epoch 19, it 19502 >> 50.10 (2.282 sec) : loss = 0.00052
INFO: epoch 19, it 19753 >> 75.20 (3.390 sec) : loss = 0.00040
INFO: epoch 19, it 20000 >> 100.00 (4.477 sec) : lr 0.0012, train loss 0.00042
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 14.9
INFO: test : error = 15.28
INFO: >>>>>>>>>>>>>>BEST PERFORMANCE, epoch 0<<<<<<<<<<<<<<<<<<
INFO: dev : error = 12.3
INFO: test : error = 13.24
