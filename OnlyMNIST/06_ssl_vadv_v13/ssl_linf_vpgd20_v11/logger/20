INFO: Running with the following configs:
	seed : 0
	device : cuda:0
	data_dir : ../../data/mnist_v13
	domain : mnist_orig
	img_size : 28
	batch_size : 100
	num_epochs : 20
	num_iters_per_epoch : 1000
	optim : sgd
	lr : 0.05
	momentum : 0.9
	l2_params : 0.0005
	max_grad_norm : 1
	scheduler_t0 : 20
	scheduler_tmult : 1
	vat_niters : 1
	vat_eps : 2.0
	vat_xi : 1e-06
	vat_consis_coef : 0.3
	lenet_depth : 28
	lenet_widen_factor : 1
	lenet_droprate : 0.3
	fc_nlayers : 1
	fc_hidden_dim : 1024
	fc_droprate : 0.3
	model_id : 10
	model_dir : ./saved_models
	eval_set : test_lbl
	ckpt_name : best_model.ckpt
	load : False

INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 0, it 251 >> 25.00 (17.513 sec) : loss = 0.37338
INFO: epoch 0, it 502 >> 50.10 (34.571 sec) : loss = 0.28819
INFO: epoch 0, it 753 >> 75.20 (51.778 sec) : loss = 0.24947
INFO: epoch 0, it 1000 >> 100.00 (67.759 sec) : lr 0.0500, train loss 0.36362
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 5.1
INFO: test : error = 4.97
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 1, it 1251 >> 25.00 (17.164 sec) : loss = 0.20351
INFO: epoch 1, it 1502 >> 50.10 (34.127 sec) : loss = 0.25278
INFO: epoch 1, it 1753 >> 75.20 (51.076 sec) : loss = 0.19287
INFO: epoch 1, it 2000 >> 100.00 (67.024 sec) : lr 0.0497, train loss 0.20801
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.9
INFO: test : error = 4.61
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 2, it 2251 >> 25.00 (17.177 sec) : loss = 0.17971
INFO: epoch 2, it 2502 >> 50.10 (34.289 sec) : loss = 0.17778
INFO: epoch 2, it 2753 >> 75.20 (51.315 sec) : loss = 0.18577
INFO: epoch 2, it 3000 >> 100.00 (67.262 sec) : lr 0.0488, train loss 0.18698
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.0
INFO: test : error = 4.17
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 3, it 3251 >> 25.00 (17.143 sec) : loss = 0.16969
INFO: epoch 3, it 3502 >> 50.10 (34.129 sec) : loss = 0.18365
INFO: epoch 3, it 3753 >> 75.20 (51.084 sec) : loss = 0.17067
INFO: epoch 3, it 4000 >> 100.00 (67.246 sec) : lr 0.0473, train loss 0.17544
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.1
INFO: test : error = 4.09
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 4, it 4251 >> 25.00 (17.197 sec) : loss = 0.16978
INFO: epoch 4, it 4502 >> 50.10 (34.121 sec) : loss = 0.16541
INFO: epoch 4, it 4753 >> 75.20 (51.053 sec) : loss = 0.12820
INFO: epoch 4, it 5000 >> 100.00 (67.093 sec) : lr 0.0452, train loss 0.16974
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.5
INFO: test : error = 4.14
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 5, it 5251 >> 25.00 (17.811 sec) : loss = 0.15635
INFO: epoch 5, it 5502 >> 50.10 (35.369 sec) : loss = 0.14711
INFO: epoch 5, it 5753 >> 75.20 (52.529 sec) : loss = 0.17324
INFO: epoch 5, it 6000 >> 100.00 (69.639 sec) : lr 0.0427, train loss 0.16262
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.7
INFO: test : error = 3.7
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 6, it 6251 >> 25.00 (17.209 sec) : loss = 0.15587
INFO: epoch 6, it 6502 >> 50.10 (34.219 sec) : loss = 0.13382
INFO: epoch 6, it 6753 >> 75.20 (51.438 sec) : loss = 0.16309
INFO: epoch 6, it 7000 >> 100.00 (67.477 sec) : lr 0.0397, train loss 0.15742
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.8
INFO: test : error = 3.57
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 7, it 7251 >> 25.00 (17.262 sec) : loss = 0.14723
INFO: epoch 7, it 7502 >> 50.10 (34.303 sec) : loss = 0.17048
INFO: epoch 7, it 7753 >> 75.20 (51.319 sec) : loss = 0.12282
INFO: epoch 7, it 8000 >> 100.00 (67.367 sec) : lr 0.0363, train loss 0.14877
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.9
INFO: test : error = 3.93
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 8, it 8251 >> 25.00 (17.359 sec) : loss = 0.11946
INFO: epoch 8, it 8502 >> 50.10 (34.562 sec) : loss = 0.13361
INFO: epoch 8, it 8753 >> 75.20 (51.526 sec) : loss = 0.10977
INFO: epoch 8, it 9000 >> 100.00 (67.607 sec) : lr 0.0327, train loss 0.14323
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.4
INFO: test : error = 3.7
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 9, it 9251 >> 25.00 (17.208 sec) : loss = 0.10586
INFO: epoch 9, it 9502 >> 50.10 (34.232 sec) : loss = 0.18075
INFO: epoch 9, it 9753 >> 75.20 (51.261 sec) : loss = 0.11674
INFO: epoch 9, it 10000 >> 100.00 (67.505 sec) : lr 0.0289, train loss 0.13777
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 4.2
INFO: test : error = 3.57
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 10, it 10251 >> 25.00 (17.170 sec) : loss = 0.15407
INFO: epoch 10, it 10502 >> 50.10 (34.201 sec) : loss = 0.12328
INFO: epoch 10, it 10753 >> 75.20 (51.284 sec) : loss = 0.12423
INFO: epoch 10, it 11000 >> 100.00 (67.355 sec) : lr 0.0250, train loss 0.13333
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.2
INFO: test : error = 3.35
INFO: >>>>>>>>>>>>>>NEW BEST PERFORMANCE<<<<<<<<
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 11, it 11251 >> 25.00 (17.215 sec) : loss = 0.09829
INFO: epoch 11, it 11502 >> 50.10 (34.240 sec) : loss = 0.12737
INFO: epoch 11, it 11753 >> 75.20 (51.510 sec) : loss = 0.16859
INFO: epoch 11, it 12000 >> 100.00 (67.628 sec) : lr 0.0211, train loss 0.12991
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.8
INFO: test : error = 3.46
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 12, it 12251 >> 25.00 (17.265 sec) : loss = 0.13400
INFO: epoch 12, it 12502 >> 50.10 (34.410 sec) : loss = 0.11849
INFO: epoch 12, it 12753 >> 75.20 (51.520 sec) : loss = 0.12758
INFO: epoch 12, it 13000 >> 100.00 (67.593 sec) : lr 0.0173, train loss 0.12447
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.4
INFO: test : error = 3.78
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 13, it 13251 >> 25.00 (17.366 sec) : loss = 0.11464
INFO: epoch 13, it 13502 >> 50.10 (34.501 sec) : loss = 0.11866
INFO: epoch 13, it 13753 >> 75.20 (51.539 sec) : loss = 0.13803
INFO: epoch 13, it 14000 >> 100.00 (67.674 sec) : lr 0.0137, train loss 0.12058
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.7
INFO: test : error = 3.46
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 14, it 14251 >> 25.00 (17.318 sec) : loss = 0.10672
INFO: epoch 14, it 14502 >> 50.10 (34.530 sec) : loss = 0.11138
INFO: epoch 14, it 14753 >> 75.20 (51.602 sec) : loss = 0.10060
INFO: epoch 14, it 15000 >> 100.00 (67.835 sec) : lr 0.0103, train loss 0.11484
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.3
INFO: test : error = 3.45
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 15, it 15251 >> 25.00 (17.366 sec) : loss = 0.10628
INFO: epoch 15, it 15502 >> 50.10 (34.447 sec) : loss = 0.09396
INFO: epoch 15, it 15753 >> 75.20 (51.437 sec) : loss = 0.11524
INFO: epoch 15, it 16000 >> 100.00 (67.538 sec) : lr 0.0073, train loss 0.11402
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.8
INFO: test : error = 3.57
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 16, it 16251 >> 25.00 (17.200 sec) : loss = 0.11071
INFO: epoch 16, it 16502 >> 50.10 (34.242 sec) : loss = 0.10774
INFO: epoch 16, it 16753 >> 75.20 (51.503 sec) : loss = 0.12765
INFO: epoch 16, it 17000 >> 100.00 (67.524 sec) : lr 0.0048, train loss 0.11058
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.7
INFO: test : error = 3.58
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 17, it 17251 >> 25.00 (17.197 sec) : loss = 0.11419
INFO: epoch 17, it 17502 >> 50.10 (34.181 sec) : loss = 0.11774
INFO: epoch 17, it 17753 >> 75.20 (51.287 sec) : loss = 0.12227
INFO: epoch 17, it 18000 >> 100.00 (67.342 sec) : lr 0.0027, train loss 0.10980
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.2
INFO: test : error = 3.5
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 18, it 18251 >> 25.00 (17.283 sec) : loss = 0.13846
INFO: epoch 18, it 18502 >> 50.10 (34.472 sec) : loss = 0.12525
INFO: epoch 18, it 18753 >> 75.20 (51.471 sec) : loss = 0.09043
INFO: epoch 18, it 19000 >> 100.00 (67.662 sec) : lr 0.0012, train loss 0.10860
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.2
INFO: test : error = 3.51
INFO: >>>>>>>>>>>>>>TRAINING<<<<<<<<<<<<<<<<<<<<
INFO: epoch 19, it 19251 >> 25.00 (17.225 sec) : loss = 0.13905
INFO: epoch 19, it 19502 >> 50.10 (34.322 sec) : loss = 0.12663
INFO: epoch 19, it 19753 >> 75.20 (51.400 sec) : loss = 0.14334
INFO: epoch 19, it 20000 >> 100.00 (67.613 sec) : lr 0.0003, train loss 0.10922
INFO: >>>>>>>>>>>>>>EVALUATING<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.3
INFO: test : error = 3.49
INFO: >>>>>>>>>>>>>>BEST PERFORMANCE, epoch 10<<<<<<<<<<<<<<<<<<
INFO: dev : error = 3.2
INFO: test : error = 3.35
